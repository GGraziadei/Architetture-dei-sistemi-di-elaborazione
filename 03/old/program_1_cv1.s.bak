.data
	v1: .double 	-32,41,29,-51,-44,53,54,4,-7,-27
		.double		2,61,44,-36,-33,36,-40,-35,62,-13
		.double		43,8,-12,-18,13,40,16,-16,-10,-30
		.double		12,38,-52,24,20,9.5,-28,1,-24,42
		.double		21,-41,28,-16,46,41,61,-63,-54,-62
		.double		-24,26,-15,18,20,37,-32,35,33,13
				
	v2: .double 	22.01,52.95,23.97,62.48,71.97,78.49,10.39,43.94,98.68,71.46
		.double		2.01,9.01,41.31,96.29,78.33,96.99,22.79,64.44,50.35,96.71
		.double		17.1,88.19,42.32,67.12,90.7,93.83,80.2,48.47,53.59,84.3
		.double		5.03,12.07,41.16,2.5,55.36,30.61,29.23,53.36,69.79,73.72
		.double		43,90.36,96.36,65.55,68.22,80.73,84.48,96.94,48.63,66.67
		.double		54.21,36.98,46.15,69.01,13.29,18.13,72.55,10.91,71.01,14
	
	v3: .double 	122.01,152.95,23.97,62.48,71.97,78.49,10.39,43.94,98.68,71.46
		.double		2.01,9.01,41.31,96.29,78.33,96.99,22.79,64.44,50.35,96.71
		.double		14.1,88.19,42.32,67.12,97.7,93.83,80.2,48.47,53.59,84.3
		.double		5.03,12.07,41.16,2.5,55.36,30.61,29.23,53.36,69.79,73.72
		.double		43,90.36,96.36,65.55,68.22,80.74,84.48,96.94,48.63,66.67
		.double		54.21,26.98,46.15,69.01,13.29,18.13,72.55,10.91,71.01,14
	
	v4: .double 	22.01,52.95,23.97,62.48,71.97,78.49,10.39,43.94,98.68,71.46
		.double		2.01,9.01,41.31,96.29,78.33,96.99,22.79,64.44,50.35,96.71
		.double		17.1,88.19,42.32,67.12,90.7,93.83,80.2,48.47,53.59,84.3
		.double		5.03,12.07,41.16,2.5,55.36,30.61,29.23,53.36,69.79,73.72
		.double		43,90.36,96.36,65.55,68.22,80.73,84.48,96.94,48.63,66.67
		.double		54.21,36.98,46.15,69.01,13.29,18.13,72.55,10.91,71.01,14
	v5: .space 480
	v6: .space 480
	v7: .space 480

.text
main: 
	daddu 	R3,  R0,  R0 #data hazard su riga 44
	daddu 	R1,  R0,  R0 
	daddu 	R4,	 R0,  R0 
	daddui 	R2,  R0,  20
	l.d f1 , v1(R4) # v1[i] 
	l.d f2 , v2(R4) # v2[i]
	l.d f3 , v3(R4) # v3[i]
	l.d f4 , v4(R4) # v4[i]
	add.d f5 , f1 , f2  # v1[i]+v2[i]
	add.d f7 , f2 , f3 # v2[i]+v3[i]

for0:
	
	mul.d f8 , f5 , f3 # ((v1[i]+v2[i]) * v3[i])
	daddui R4 , R4 , 8 # incrementa offset di 8 byte
	mul.d f6 , f1 , f4 # v4[i]*v1[i]
	add.d f9 , f8 , f4 # ((v1[i]+v2[i]) * v3[i])+v4[i];
	div.d f6 , f9 , f6 # v5[i]/(v4[i]*v1[i]);
	l.d f1 , v1(R4) # v1[i] 
	l.d f2 , v2(R4) # v2[i]
	add.d f5 , f1 , f2  # v1[i]+v2[i]
	l.d f3 , v3(R4) # v3[i]
	add.d f7 , f2 , f3 # v2[i]+v3[i]
	mul.d f8 , f5 , f3 # ((v1[i]+v2[i]) * v3[i])
	l.d f4 , v4(R4) # v4[i]
	daddui R4 , R4 , 8 # incrementa offset di 8 byte
	mul.d f10 , f1 , f4 # v4[i]*v1[i]
	add.d f11 , f8 , f4 # ((v1[i]+v2[i]) * v3[i])+v4[i];
	s.d f9 , v5(R3)
	s.d f6 , v6(R3)
	mul.d f7 , f7 , f6 # v6[i]*(v2[i]+v3[i]);
	s.d f7 , v7(R3)
	daddui R3 , R3 , 8 # incrementa offset di 8 byte
	
	div.d f10 , f11 , f10 # v5[i]/(v4[i]*v1[i]);
	l.d f1 , v1(R4) # v1[i] 
	l.d f2 , v2(R4) # v2[i]
	add.d f5 , f1 , f2  # v1[i]+v2[i]
	l.d f3 , v3(R4) # v3[i]
	add.d f7 , f2 , f3 # v2[i]+v3[i]
	mul.d f8 , f5 , f3 # ((v1[i]+v2[i]) * v3[i])
	l.d f4 , v4(R4) # v4[i]
	mul.d f6 , f1 , f4 # v4[i]*v1[i]
	add.d f9 , f8 , f4 # ((v1[i]+v2[i]) * v3[i])+v4[i];
	daddui R4 , R4 , 8 # incrementa offset di 8 byte
	s.d f11 , v5(R3)
	s.d f10 , v6(R3)
	mul.d f7 , f7 , f10 # v6[i]*(v2[i]+v3[i]);
	s.d f7 , v7(R3)
	
	
	daddui R3 , R3 , 8 # incrementa offset di 8 byte
	
	div.d f6 , f9 , f6 # v5[i]/(v4[i]*v1[i]);
	daddu R5, R0, R3
	l.d f1 , v1(R4) # v1[i] 
	l.d f2 , v2(R4) # v2[i]
	add.d f5 , f1 , f2  # v1[i]+v2[i]
	l.d f3 , v3(R4) # v3[i]
	add.d f7 , f2 , f3 # v2[i]+v3[i]
	l.d f4 , v4(R4) # v4[i]
	s.d f9 , v5(R3)
	s.d f6 , v6(R3)
	daddui R3 , R3 , 8 # incrementa offset di 8 byte
	mul.d f7 , f7 , f6 # v6[i]*(v2[i]+v3[i]);
	daddui R1, R1, 1
	bne R1,  R2,  for0
	s.d f7 , v7(R5)
	
	HALT